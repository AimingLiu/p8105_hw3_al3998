---
title: "p8105_hw3_al3998"
author: "AimingLiu"
date: "10/3/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(patchwork)
library(dplyr)
```

# Load the data from the p8105.datasets
```{r}
library(p8105.datasets)
data("instacart")
```

```{r}
  aisle_form = instacart %>% 
  group_by(aisle) %>%
  summarize(n = n()) %>% 
  arrange(desc(n)) 
  aisle_num = nrow(aisle_form) 
```
 It can be concluded that the row number of aisle is  `r nrow(aisle_form)` and  the most items ordered from `r pull(aisle_form,aisle)[1]`
 
# Making a plot
```{r  fig.height = 10, fig.width = 15}
  aisle_form %>% 
  filter(n > 10000) %>% 
  ggplot(aes(x = aisle,y = n,fill = aisle))+
    geom_col()+coord_flip()+
  labs(
    title = "Plot about the number of items ordered in each aisle",
    x = "number of items",
    y = "aisle" ,
    caption = "Data from the instacart")+
    theme(legend.position = "bottom")
```
# Making a table showing the three most popular items 
```{r}
 filter(instacart,aisle %in% c("baking ingredients","dog food care","packaged vegetables fruits")) %>% 
 group_by(aisle,product_name) %>% 
 summarise(n_aisle_product = n()) %>%
 group_by(aisle) %>%
 filter(min_rank(desc(n_aisle_product))<4) %>% 
 knitr::kable()
 
```
#Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week
```{r}
  filter(instacart,product_name %in% c("Pink Lady Apples","Coffee Ice Cream")) %>% 
  group_by(product_name,order_dow) %>% 
  summarize(mean_order = mean(order_hour_of_day)) %>% 
  mutate(order_dow = recode(order_dow,"0"="Sunday","1"="Monday","2"="Tuesday","3"="Wednesday","4"="Thursday","5"="Friday","6"="Saturday")) %>% 
 pivot_wider(names_from = order_dow,
             values_from = mean_order) %>% 
  knitr::kable()
 
```

#Problem 2
```{r}
  library(p8105.datasets)
  data("brfss_smart2010")
```


```{r}
  brfss_form = brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic =="Overall Health") %>% 
  drop_na(response) %>% 
  mutate(response = factor(response,
                           levels = c("Poor","Fair","Good","Very good","Excellent"),
                           ordered = is.ordered(response))) %>% 
  arrange(desc(response))  
```

```{r}
  loco_2002 = filter(brfss_form ,year == "2002") %>% 
  group_by(locationabbr) %>% 
  summarise(count_state =n()) %>% 
  filter(count_state >= 7) 
```

In 2002,the abbreviation of the states which were observed at 7 or more locations were `r pull(loco_2002,locationabbr)`

```{r}
  loco_2010 = filter(brfss_form ,year == "2010") %>% 
  group_by(locationabbr) %>% 
  summarise(count_state =n()) %>% 
  filter(count_state >= 7) 
```
In 2010,the abbreviation of the states which were observed at 7 or more locations were `r pull(loco_2010,locationabbr)`

```{r}
  excellent_form = brfss_form %>% 
  filter(response == "Excellent") %>% 
  group_by(locationabbr,year) %>% 
  summarize(mean_data = mean(data_value,na.rm = TRUE)) 

```

```{r}
  average_plot = excellent_form %>% 
  ggplot(aes(x = year,y = mean_data,color = locationabbr ))+
  geom_line()+
  labs(
    title = "Spaghetti Plot",
    x = "Year",
    y = "average of the data value"
  ) 
  
average_plot
```
```{r fig.height = 5, fig.width = 15}
 ny_data_1 = brfss_form %>% 
 filter(locationabbr == "NY" & year == "2006") %>% 
 select(locationdesc,response,data_value) %>% 
 ggplot(aes(x = locationdesc ,y = data_value ,color = response, group = response))+
 geom_point(size = 4,alpha = .7)+geom_line() +
  labs(
     title = " distribution of data_value for responses in 2006",
     x = "locationdesc",
     y = "data_value"
  )+ theme(legend.position = "bottom")


 ny_data_2 = brfss_form %>% 
 filter(locationabbr == "NY" & year == "2010") %>% 
 select(locationdesc,response,data_value) %>% 
 ggplot(aes(x = locationdesc ,y = data_value ,color = response ,group = response))+
 geom_point(size = 4,alpha = .7)+geom_line() +
   labs(
     title = " distribution of data_value for responses in 2010",
     x = "locationdesc",
     y = "data_value"
  )+ theme(legend.position = "bottom")

 
 ny_data_1+ny_data_2
```

#Problem 3
```{r}
  accel_data = read_csv("./accel_data.csv") %>% 
  janitor::clean_names() %>% 
    mutate(weekday_end = case_when(day =="Monday" ~ "weekday",
                                    day =="Tuesday" ~ "weekday",
                                    day =="Wednesday" ~ "weekday",
                                    day =="Thursday" ~ "weekday",
                                    day =="Friday" ~ "weekday",
                                    day =="Saturday" ~ "weekend",
                                    day =="Sunday" ~ "weekend"
                                )) %>% 
  arrange(week,day_id) %>%
  select(1:3,weekday_end,everything()) %>% 
  mutate_if(is.double,as.integer)
  
```
For the resulting dataset,there are `r nrow(accel_data)` observations and `r ncol(accel_data)` variables.The data set also include the information about week,day id,weekday and weekend.

```{r}
         total_accel_data = accel_data %>% 
          mutate(accel_sum = rowSums(accel_data[,5:1444])) %>% 
          select(week:weekday_end, accel_sum) 
           
         knitr::kable(total_accel_data)
  
```

```{r}
 total_accel_data %>% 
  select(week,day,accel_sum) %>% 
  ggplot(aes(x = week,y = accel_sum,color = day))+
  geom_point(alpha = .5)+geom_line()+
  labs(
    title = "24-hour activity time courses ",
    x = "Week",
    y = "accel_sum"
  )
```








